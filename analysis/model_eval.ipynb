{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Opening notebook remotely on MacOS --> jupyter-notebook --no-browser --port=9090\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    Opening notebook remotely on MacOS --> jupyter-notebook --no-browser --port=9090\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No file or directory found at orig_example.h5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m orig_model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morig_example.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m aug_model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maug_example.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m orig_model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43morig_model_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m aug_model \u001b[38;5;241m=\u001b[39m load_model(aug_model_name)\n",
      "File \u001b[0;32m/usr/local/python-env/py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/python-env/py39/lib/python3.9/site-packages/keras/saving/save.py:206\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath_str, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    205\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mexists(filepath_str):\n\u001b[0;32m--> 206\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo file or directory found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    208\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39misdir(filepath_str):\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saved_model_load\u001b[38;5;241m.\u001b[39mload(filepath_str, \u001b[38;5;28mcompile\u001b[39m, options)\n",
      "\u001b[0;31mOSError\u001b[0m: No file or directory found at orig_example.h5"
     ]
    }
   ],
   "source": [
    "orig_model_name = \"orig_example.h5\"\n",
    "aug_model_name = \"aug_example.h5\"\n",
    "orig_model = load_model(orig_model_name)\n",
    "aug_model = load_model(aug_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_dir = \"/s/bach/a/class/cs435/cs435a/\"\n",
    "image_dir = \"CS435_Plant_Data_v2_augment-v2/2023-11-15-231056/\"\n",
    "\n",
    "orig_test = \"splits/original/orig_test.csv\"\n",
    "aug_test = \"splits/augmented/aug_test.csv\"\n",
    "\n",
    "orig_test_path = shared_dir+image_dir+orig_test\n",
    "aug_test_path = shared_dir+image_dir+aug_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7166 validated image filenames belonging to 31 classes.\n",
      "Found 21580 validated image filenames belonging to 31 classes.\n"
     ]
    }
   ],
   "source": [
    "orig_test_df = pd.read_csv(orig_test_path)\n",
    "aug_test_df = pd.read_csv(aug_test_path)\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255) #normalize from [0,255] to [0,1]\n",
    "orig_test_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=orig_test_df, \n",
    "    x_col='path_to_shared',\n",
    "    y_col='class_name',  \n",
    "    target_size=(224, 224),\n",
    "    batch_size=4,\n",
    "    class_mode='categorical', \n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "aug_test_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=aug_test_df, \n",
    "    x_col='path_to_shared',\n",
    "    y_col='class_name',  \n",
    "    target_size=(224, 224),\n",
    "    batch_size=1,\n",
    "    class_mode='categorical', \n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic metrics: accuracy, precision, recall, f1-score\n",
    "def evaluate_model_metrics(model, test_generator):\n",
    "    accuracy = model.evaluate(test_generator)[1]\n",
    "    print(f\"Test Accuracy: {evaluation[1]}\")\n",
    "\n",
    "    predictions = model.predict(test_generator)\n",
    "    predicted_classes = [np.argmax(pred) for pred in predictions]\n",
    "\n",
    "    true_classes = test_generator.classes\n",
    "\n",
    "    class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "    report = classification_report(true_classes, predicted_classes, target_names=class_labels, output_dict=True)\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More advanced metrics: Confusion Matrix\n",
    "def create_model_confusion_matrix(model, test_generator, model_name):\n",
    "    predictions = model.predict(test_generator)\n",
    "    \n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "    label_map = {label: index for index, label in enumerate(test_generator.class_indices)}\n",
    "\n",
    "    true_classes = test_df['class_name'].map(label_map).values\n",
    "\n",
    "    conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
    "\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='g')\n",
    "    plt.xlabel('Predicted labels')\n",
    "    plt.ylabel('True labels')\n",
    "    plt.title('Confusion Matrix')\n",
    "\n",
    "    plt.savefig(model_name+'_aug_confusion_matrix.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** EVALUATING MODEL TRAINED ON ORIGINAL DATA ***\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'orig_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*** EVALUATING MODEL TRAINED ON ORIGINAL DATA ***\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m orig_orig_test_report \u001b[38;5;241m=\u001b[39m evaluate_model_metrics(\u001b[43morig_model\u001b[49m, orig_test_generator)\n\u001b[1;32m      3\u001b[0m orig_aug_test_report \u001b[38;5;241m=\u001b[39m evaluate_model_metrics(orig_model, aug_test_generator)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*** EVALUATIONS ON ORIGINAL TEST DATA ***\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'orig_model' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"*** EVALUATING MODEL TRAINED ON ORIGINAL DATA ***\")\n",
    "orig_orig_test_report = evaluate_model_metrics(orig_model, orig_test_generator)\n",
    "orig_aug_test_report = evaluate_model_metrics(orig_model, aug_test_generator)\n",
    "\n",
    "print(\"*** EVALUATIONS ON ORIGINAL TEST DATA ***\")\n",
    "orig_orig_df = pd.Dataframe(orig_orig_test_report).transpose()\n",
    "display(orig_orig_df)\n",
    "\n",
    "print(\"*** EVALUATIONS ON AUGMENTED TEST DATA ***\")\n",
    "orig_aug_df = pd.Dataframe(orig_aug_test_report).transpose()\n",
    "display(orig_aug_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** EVALUATING MODEL TRAINED ON ORIGINAL DATA ***\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'aug_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*** EVALUATING MODEL TRAINED ON ORIGINAL DATA ***\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m aug_orig_test_report \u001b[38;5;241m=\u001b[39m evaluate_model_metrics(\u001b[43maug_model\u001b[49m, orig_test_generator)\n\u001b[1;32m      3\u001b[0m aug_aug_test_report \u001b[38;5;241m=\u001b[39m evaluate_model_metrics(aug_model, aug_test_generator)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*** EVALUATIONS ON ORIGINAL TEST DATA ***\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'aug_model' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"*** EVALUATING MODEL TRAINED ON ORIGINAL DATA ***\")\n",
    "aug_orig_test_report = evaluate_model_metrics(aug_model, orig_test_generator)\n",
    "aug_aug_test_report = evaluate_model_metrics(aug_model, aug_test_generator)\n",
    "\n",
    "print(\"*** EVALUATIONS ON ORIGINAL TEST DATA ***\")\n",
    "aug_orig_df = pd.Dataframe(aug_orig_test_report).transpose()\n",
    "display(aug_orig_df)\n",
    "\n",
    "print(\"*** EVALUATIONS ON AUGMENTED TEST DATA ***\")\n",
    "aug_aug_df = pd.Dataframe(aug_aug_test_report).transpose()\n",
    "display(aug_aug_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
